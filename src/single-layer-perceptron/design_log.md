## Perceptron for AND Gate

- Inputs: 2 binary features
- Outputs: Binary result (0 or 1)
- Activation: Step function
- Training: Perceptron Learning Rule
- Decision logic: Adjust weights based on prediction error scaled by learning rate and input

Design rationale:
We used the Perceptron learning rule because it's simple, intuitive, and provably converges for linearly separable problems like AND/OR.
